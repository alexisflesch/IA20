---
title: "Chapitre 6 ‚Äî Deep Learning et IA G√©n√©rative"
---

## üéØ Objectifs d'apprentissage

- **Comprendre** les architectures sp√©cialis√©es du Deep Learning.
- **D√©mystifier** la Vision par Ordinateur (CNN) et le Traitement du Langage (Transformers).
- **Saisir** le fonctionnement des IA G√©n√©ratives modernes (LLM, Diffusion).

---

## 1. Vision par Ordinateur : Les CNN

Comment une IA reconna√Æt-elle un chat dans une image ? Pas en regardant les pixels un par un (√ßa ne marche pas si le chat bouge d'un centim√®tre). Elle utilise des **R√©seaux de Neurones Convolutifs (CNN)**.

### 1.1 Le principe de la Convolution

L'id√©e est inspir√©e du cortex visuel animal. Au lieu de connecter tous les neurones √† tous les pixels, on utilise des **filtres** (ou noyaux) de petite taille (ex: 3x3 pixels).

On fait glisser ce filtre sur toute l'image.
*   Un filtre peut √™tre sp√©cialis√© pour d√©tecter les **lignes verticales**.
*   Un autre pour les **lignes horizontales**.
*   Un autre pour les **coins**.

### 1.2 Padding et Stride

Deux concepts cl√©s pour contr√¥ler la taille de sortie :
*   **Padding (Rembourrage)** : Ajouter des z√©ros autour de l'image avant de passer le filtre. Cela permet de garder la m√™me taille d'image en sortie (sinon elle r√©tr√©cit √† chaque couche).
*   **Stride (Pas)** : De combien de pixels on d√©cale le filtre √† chaque fois.
    *   Stride = 1 : On glisse pixel par pixel (pr√©cis).
    *   Stride = 2 : On saute un pixel sur deux (r√©duit la taille de sortie par 2).

### 1.3 L'architecture en couches

C'est un assemblage hi√©rarchique :
1.  **Premi√®res couches** : D√©tectent des formes simples (bords, textures).
2.  **Couches moyennes** : Assemblent ces formes (≈ìil, oreille, roue).
3.  **Derni√®res couches** : Reconnaissent des objets entiers (visage, voiture).

C'est ce qu'on appelle l'**extraction de caract√©ristiques** (Feature Extraction) automatique. Avant le Deep Learning, les humains devaient coder ces r√®gles √† la main !

---

## 2. Traitement du Langage (NLP) : Les Transformers

Jusqu'en 2017, les IA lisaient le texte mot √† mot (de gauche √† droite), comme nous. Elles oubliaient souvent le d√©but de la phrase quand elles arrivaient √† la fin.
Puis est arriv√© l'article "Attention Is All You Need" (Google), introduisant les **Transformers**.

### 2.1 Le M√©canisme d'Attention

Le Transformer lit toute la phrase **d'un coup** (en parall√®le).
Pour chaque mot, il calcule son lien avec *tous* les autres mots de la phrase. C'est l'**Attention**.

*Exemple* : "L'animal ne traverse pas la rue car **il** est trop fatigu√©."
*   Pour comprendre le mot "**il**", le mod√®le porte une forte "attention" au mot "**animal**" et une faible attention au mot "rue".
*   Si la phrase √©tait "...car **elle** est trop large", l'attention de "**elle**" se porterait sur "**rue**".

C'est cette capacit√© √† saisir le contexte (Contextual Embedding) qui a tout chang√©.

---

## 3. L'IA G√©n√©rative

L'IA classique (Discriminative) sert √† **classer** (Chat ou Chien ?).
L'IA G√©n√©rative sert √† **cr√©er** de nouvelles donn√©es qui ressemblent aux donn√©es d'entra√Ænement.

### 3.1 Les LLM (Large Language Models)

GPT (Generative Pre-trained Transformer) est un Transformer g√©ant entra√Æn√© sur une t√¢che simple : **Pr√©dire le mot suivant**.

*   *Entra√Ænement* : On lui donne des milliards de textes internet. On cache la fin des phrases et on lui demande de deviner. S'il se trompe, on corrige ses poids (Backpropagation).
*   *R√©sultat* : √Ä force de jouer √† ce jeu, il finit par apprendre la grammaire, les faits historiques, le raisonnement logique, et m√™me le code informatique.
*   *Temp√©rature* : C'est un param√®tre qui contr√¥le la cr√©ativit√©.
    *   Temp√©rature 0 : Il choisit toujours le mot le plus probable (r√©ponse robotique).
    *   Temp√©rature 1 : Il prend des risques (r√©ponse cr√©ative mais parfois incoh√©rente).

### 3.2 La G√©n√©ration d'Images (Mod√®les de Diffusion)

C'est la technologie derri√®re Midjourney ou DALL-E.

*   **Principe** : On prend une image de chat et on ajoute progressivement du "bruit" (de la neige t√©l√©visuelle) jusqu'√† ce qu'elle soit m√©connaissable.
*   **Apprentissage** : On entra√Æne un r√©seau de neurones √† faire l'inverse : partir du bruit et **retrouver l'image originale** (Denoising).
*   **G√©n√©ration** : Pour cr√©er une image, on part d'un bruit totalement al√©atoire et on demande au r√©seau de le "nettoyer" en le guidant avec une description textuelle ("Un chat dans l'espace").

---

**Prochain chapitre** : [Chapitre 7 ‚Äî √âthique, Limites et Soci√©t√©](/cours/CM7/)
