---
title: "Chapitre 6 ‚Äî Deep Learning et IA G√©n√©rative"
---

## üéØ Objectifs d'apprentissage

- **Comprendre** les architectures sp√©cialis√©es du Deep Learning.
- **D√©mystifier** la Vision par Ordinateur (CNN) et le Traitement du Langage (Transformers).
- **Saisir** le fonctionnement des IA G√©n√©ratives modernes (LLM, Diffusion).

---

## 1. Vision par Ordinateur : Les CNN

Comment une IA reconna√Æt-elle un chat dans une image ? Pas en regardant les pixels un par un (√ßa ne marche pas si le chat bouge d'un centim√®tre). Elle utilise des **R√©seaux de Neurones Convolutifs (CNN)**.

### 1.1 Le principe de la Convolution

L'id√©e est inspir√©e du cortex visuel animal. Au lieu de connecter tous les neurones √† tous les pixels, on utilise des **filtres** (ou noyaux) de petite taille (ex: 3x3 pixels).

> **D√©finition Math√©matique** :
> La convolution discr√®te en 2D d'une image $I$ par un noyau $K$ est donn√©e par :
> $$ (I * K)(x, y) = \sum_{i} \sum_{j} I(x-i, y-j) \cdot K(i, j) $$
> C'est une somme pond√©r√©e des pixels voisins.

<div style="display: flex; align-items: center; justify-content: center; gap: 20px; flex-wrap: wrap; margin: 20px 0;">
  <div style="text-align: center;">
    <p style="margin-bottom: 5px;"><strong>Image (5x5)</strong></p>
    <svg width="150" height="150" viewBox="0 0 150 150" style="background: white;">
      <defs>
        <pattern id="grid" width="30" height="30" patternUnits="userSpaceOnUse">
          <rect width="30" height="30" fill="white" stroke="#ccc" stroke-width="1"/>
        </pattern>
      </defs>
      <rect width="150" height="150" fill="url(#grid)" stroke="black" stroke-width="2"/>
      <rect x="0" y="0" width="90" height="90" fill="red" fill-opacity="0.2" stroke="red" stroke-width="3" stroke-dasharray="5,5"/>
    </svg>
  </div>
  <div style="font-size: 24px; text-align: center;">‚ûú</div>
  <div style="text-align: center;">
    <p style="margin-bottom: 5px;"><strong>Feature Map (3x3)</strong></p>
    <svg width="90" height="90" viewBox="0 0 90 90" style="background: white;">
      <defs>
        <pattern id="grid3" width="30" height="30" patternUnits="userSpaceOnUse">
          <rect width="30" height="30" fill="#e0f7fa" stroke="#006064" stroke-width="1"/>
        </pattern>
      </defs>
      <rect width="90" height="90" fill="url(#grid3)" stroke="black" stroke-width="2"/>
      <rect x="0" y="0" width="30" height="30" fill="#00bcd4" stroke="black" stroke-width="2"/>
    </svg>
  </div>
</div>

On fait glisser ce filtre sur toute l'image.
*   Un filtre peut √™tre sp√©cialis√© pour d√©tecter les **lignes verticales**.
*   Un autre pour les **lignes horizontales**.
*   Un autre pour les **coins**.

> **Visualisation : Le Filtre Glissant**
> Imaginez que vous regardez un grand tableau √† travers un petit cadre en carton (3x3 cm).
> Vous d√©placez ce cadre case par case. √Ä chaque position, vous notez si ce que vous voyez ressemble au motif que vous cherchez (ex: une ligne verticale).
> Vous obtenez une nouvelle grille (la "Feature Map") qui indique o√π se trouvent les lignes verticales dans l'image.

### 1.2 L'Observable Interactif

Pour bien comprendre, rien de mieux que de manipuler soi-m√™me les pixels.
Ci-dessous, vous pouvez voir comment le calcul se fait (partie 1) et l'effet des diff√©rents filtres sur une vraie image (partie 2).

<iframe src="/observables/convolution/index.html" width="100%" height="600px" style="border: none; background: #f9f9f9; border-radius: 8px;"></iframe>

### 1.3 Padding et Stride

Deux concepts cl√©s pour contr√¥ler la taille de sortie :
*   **Padding (Rembourrage)** : Ajouter des z√©ros autour de l'image avant de passer le filtre. Cela permet de garder la m√™me taille d'image en sortie (sinon elle r√©tr√©cit √† chaque couche).
*   **Stride (Pas)** : De combien de pixels on d√©cale le filtre √† chaque fois.
    *   Stride = 1 : On glisse pixel par pixel (pr√©cis).
    *   Stride = 2 : On saute un pixel sur deux (r√©duit la taille de sortie par 2).

### 1.4 La Non-Lin√©arit√© (ReLU)

Apr√®s chaque convolution, on applique une fonction d'activation. La plus courante est **ReLU (Rectified Linear Unit)**.
$$ f(x) = \max(0, x) $$
Concr√®tement, elle remplace toutes les valeurs n√©gatives par z√©ro.
*   **Pourquoi ?** Pour casser la lin√©arit√© (sinon empiler des convolutions revient √† faire une seule grosse convolution).
*   **Effet visuel** : Elle garde les caract√©ristiques d√©tect√©es (positives) et supprime le "bruit" ou les anti-caract√©ristiques (n√©gatives).

### 1.5 Le Pooling (Sous-√©chantillonnage)

Pour r√©duire la taille de l'image (et donc le nombre de calculs) et rendre l'IA invariante aux petites translations, on utilise le **Pooling**.
Le plus connu est le **Max Pooling**.
*   On prend une fen√™tre (ex: 2x2).
*   On ne garde que la **valeur maximale** de cette fen√™tre.
*   On jette les 3 autres pixels.

> **Analogie** : Si vous cherchez "O√π est Charlie ?", peu importe qu'il soit au pixel (10,10) ou (11,11). L'important est de savoir qu'il est dans la zone "en haut √† gauche". Le Pooling r√©sume l'information : "Oui, il y a un motif int√©ressant dans cette zone".

### 1.6 La Classification Finale (Fully Connected)

Une fois que les couches de convolution et de pooling ont extrait les caract√©ristiques (oreilles, moustaches, queue...), on obtient une s√©rie de petites cartes (Feature Maps).
1.  **Flattening (Aplatissement)** : On transforme toutes ces cartes 2D en un long vecteur 1D.
2.  **Fully Connected (Dense)** : On connecte ce vecteur √† un r√©seau de neurones classique (MLP).
3.  **Softmax** : La derni√®re couche donne les probabilit√©s (ex: Chat 80%, Chien 20%).

---

## 2. Architectures C√©l√®bres

L'histoire du Deep Learning est pav√©e de mod√®les l√©gendaires qui ont gagn√© le concours ImageNet.

*   **LeNet-5 (1998)** : Yann LeCun. Pour lire les ch√®ques (chiffres manuscrits). Tr√®s simple (2 convolutions).
*   **AlexNet (2012)** : Le "Big Bang". Premier CNN profond sur GPU. A √©cras√© la concurrence.
*   **VGG (2014)** : Tr√®s profond, utilise uniquement des petits filtres 3x3.
*   **ResNet (2015)** : Introduit les "connexions r√©siduelles" (skip connections) pour entra√Æner des r√©seaux ultra-profonds (152 couches) sans perdre le signal.

---

**Prochain chapitre** : [Chapitre 7 ‚Äî √âthique, Limites et Soci√©t√©](/cours/CM7/)

