---
title: "Chapitre 7 ‚Äî √âthique, Limites et Soci√©t√©"
---

## üéØ Objectifs d'apprentissage

- **D√©velopper** un esprit critique face au "Hype" de l'IA.
- **Comprendre** les m√©canismes des biais algorithmiques et leurs cons√©quences sociales.
- **Conna√Ætre** les enjeux d'explicabilit√© (Black Box).
- **Appr√©hender** le cadre l√©gal (RGPD, AI Act) et l'impact environnemental.

---

## 1. Les Biais Algorithmiques

On entend souvent : *"L'ordinateur est neutre, c'est des maths."* **C'est faux.**
Une IA est le reflet des donn√©es sur lesquelles elle a √©t√© entra√Æn√©e. Si les donn√©es contiennent les pr√©jug√©s de la soci√©t√©, l'IA va les apprendre et les amplifier.

### 1.1 Exemples c√©l√®bres
*   **Recrutement (Amazon)** : Un algo entra√Æn√© sur 10 ans de CV (majoritairement masculins dans la tech) a appris √† p√©naliser le mot "femme" ou les noms d'√©coles f√©minines. Il a d√ª √™tre abandonn√©.
*   **Justice (COMPAS)** : Un logiciel am√©ricain pr√©disant la r√©cidive attribuait syst√©matiquement un risque plus √©lev√© aux personnes noires, √† dossier √©gal.
*   **Reconnaissance faciale** : Les mod√®les marchent souvent moins bien sur les peaux fonc√©es car les datasets d'entra√Ænement contiennent surtout des personnes blanches.

### 1.2 D'o√π vient le biais ?
1.  **Biais de donn√©es** : L'√©chantillon n'est pas repr√©sentatif de la population.
2.  **Biais historique** : La r√©alit√© elle-m√™me est biais√©e (ex: √©carts de salaire H/F), l'IA ne fait que le constater et le reproduire.

---

## 2. S√©curit√© et Robustesse (Attaques Adverses)

Les r√©seaux de neurones sont fragiles. On peut tromper une IA avec des **Exemples Adverses**.
Il suffit d'ajouter un bruit invisible √† l'≈ìil nu sur une photo de Panda pour que l'IA soit s√ªre √† 99% que c'est un Gibbon.
Cela pose un √©norme probl√®me de s√©curit√© : imaginez un panneau "Stop" avec un autocollant sp√©cial qui le fait passer pour un panneau "Limitation 100" aux yeux d'une voiture autonome.

---

## 3. L'Explicabilit√© (XAI) et la "Bo√Æte Noire"

Les r√©seaux de neurones profonds (Deep Learning) sont des **Black Boxes**.
On sait ce qui rentre (Input) et ce qui sort (Output), mais les millions de calculs interm√©diaires sont illisibles pour un humain.

### Pourquoi est-ce grave ?
*   **Droit √† l'explication** : Si une banque vous refuse un pr√™t ou si une IA m√©dicale diagnostique un cancer, vous avez le droit de savoir **pourquoi**. "L'ordinateur a dit non" n'est pas acceptable juridiquement ni √©thiquement.
*   **D√©bogage** : Si on ne comprend pas comment l'IA d√©cide, on ne peut pas corriger ses erreurs (ex: une voiture autonome qui confond la lune et un feu orange).

---

## 4. Impact Environnemental

L'IA "virtuelle" a un co√ªt physique bien r√©el.

*   **Entra√Ænement** : Entra√Æner un mod√®le comme GPT-4 consomme autant d'√©lectricit√© qu'une petite ville pendant des mois.
*   **Inf√©rence** : Chaque requ√™te √† ChatGPT consomme de l'eau (pour refroidir les serveurs) et de l'√©lectricit√©. Une recherche Google "IA" consomme 10x √† 30x plus qu'une recherche classique.
*   **Mat√©riel** : La fabrication des GPU n√©cessite des terres rares et de l'eau.

---

## 5. Cadre L√©gal et R√©gulation

L'Europe est pionni√®re dans la r√©gulation de l'IA.

### 5.1 Le RGPD (2018)
L'article 22 prot√®ge les citoyens contre les d√©cisions **enti√®rement automatis√©es** ayant un effet juridique. Un humain doit toujours pouvoir intervenir ("Human in the loop").

### 5.2 L'AI Act (2024)
C'est la premi√®re loi globale sur l'IA. Elle classe les IA par niveau de risque :
1.  **Risque Inacceptable (Interdit)** : Notation sociale (comme en Chine), manipulation subliminale, reconnaissance faciale de masse en temps r√©el dans l'espace public.
2.  **Haut Risque (R√©gul√©)** : IA dans la sant√©, l'√©ducation, le recrutement, la justice. Obligation de transparence, de qualit√© des donn√©es et de supervision humaine.
3.  **Risque Limit√©** : Chatbots (doivent dire qu'ils sont des robots), Deepfakes (doivent √™tre marqu√©s comme tels).

---

## 6. Avenir du Travail

L'IA ne va probablement pas "remplacer" les humains, mais **les humains qui utilisent l'IA vont remplacer ceux qui ne l'utilisent pas**.
On se dirige vers une collaboration Homme-Machine (IA Augment√©e) plut√¥t qu'un grand remplacement, m√™me si certains m√©tiers r√©p√©titifs ou bas√©s sur la synth√®se d'information seront fortement impact√©s.

---

**Fin du cours !**
