---
title: "Chapitre 5 ‚Äî R√©seaux de Neurones (Perceptron & MLP)"
---

## üéØ Objectifs d'apprentissage

√Ä l'issue de ce chapitre, vous serez capable de :
- Comprendre le principe du neurone artificiel (perceptron)
- Identifier les fonctions d'activation et leur r√¥le
- Comprendre l'architecture d'un r√©seau multicouche
- Saisir l'intuition de la descente de gradient
- Conna√Ætre les grandes familles de r√©seaux profonds

---

## 1. Du perceptron au neurone artificiel

### 1.1 Histoire : le perceptron de Rosenblatt (1957)

Le **perceptron** est le premier mod√®le de neurone artificiel, invent√© par Frank Rosenblatt en 1957. C'est un classifieur lin√©aire binaire inspir√© du fonctionnement d'un neurone biologique.

### 1.2 Fonctionnement math√©matique

Un perceptron prend en entr√©e un vecteur $\mathbf{x} = (x_1, x_2, ..., x_n)$ et calcule :

$$
y = \text{sign}(w_1 x_1 + w_2 x_2 + ... + w_n x_n + b)
$$

Ou de mani√®re plus compacte :

$$
y = \text{sign}(\mathbf{w} \cdot \mathbf{x} + b)
$$

O√π :
- $\mathbf{w} = (w_1, w_2, ..., w_n)$ : **vecteur de poids** (coefficients)
- $b$ : **biais** (bias), d√©calage vertical
- $\text{sign}(z)$ : fonction qui renvoie +1 si $z \geq 0$, sinon -1

**Interpr√©tation g√©om√©trique** : Le perceptron trace une fronti√®re lin√©aire (droite en 2D, plan en 3D, hyperplan en dimension sup√©rieure) qui s√©pare l'espace en deux r√©gions.

### 1.3 Visualisation interactive

<iframe class="embedded-notebook" src="/observables/perceptron/" width="100%" height="900" frameborder="0"></iframe>

**Exp√©rimentez** :
1. Ajoutez des points bleus (classe +1) avec un clic gauche
2. Ajoutez des points roses (classe -1) avec un clic droit
3. Ajustez les poids $w_1$, $w_2$ et le biais $b$ pour s√©parer les classes
4. Observez comment la droite noire (fronti√®re de d√©cision) bouge
5. Les points mal class√©s sont entour√©s d'un cercle rouge

**Question** : Pouvez-vous s√©parer deux classes dispos√©es en cercles concentriques avec un perceptron ? Pourquoi ?

---

## 2. Limitations du perceptron : le probl√®me XOR

Le perceptron ne peut classifier que des donn√©es **lin√©airement s√©parables**. 

### Exemple : la fonction XOR

| $x_1$ | $x_2$ | XOR |
|-------|-------|-----|
| 0     | 0     | 0   |
| 0     | 1     | 1   |
| 1     | 0     | 1   |
| 1     | 1     | 0   |

Ces 4 points ne peuvent pas √™tre s√©par√©s par une seule droite ! C'est la **crise du perceptron** des ann√©es 1970.

**Solution** : Empiler plusieurs perceptrons en couches ‚Üí **r√©seau multicouche**.

---

## 3. R√©seaux de neurones multicouches (MLP)

### 3.1 Architecture

Un **Multi-Layer Perceptron (MLP)** est compos√© de :
- **Couche d'entr√©e** : les features $x_1, x_2, ..., x_n$
- **Couches cach√©es** : une ou plusieurs couches de neurones
- **Couche de sortie** : la pr√©diction $\hat{y}$

```
Entr√©e     Couche cach√©e     Sortie
  x‚ÇÅ  \      üîµ           \
       \    /  \           üîµ  ‚Üí  ≈∑
  x‚ÇÇ  --üîµ      üîµ        /
       /    \  /         
  x‚ÇÉ  /      üîµ         
```

### 3.2 Calcul dans un neurone

Chaque neurone de la couche cach√©e calcule :

$$
h_j = f\left(\sum_{i} w_{ji} x_i + b_j\right)
$$

O√π $f$ est une **fonction d'activation** non lin√©aire.

---

## 4. Fonctions d'activation

Les fonctions d'activation introduisent de la **non-lin√©arit√©**, permettant au r√©seau d'apprendre des relations complexes.

### 4.1 Sigmo√Øde

$$
\sigma(z) = \frac{1}{1 + e^{-z}}
$$

- Sort entre 0 et 1
- Historiquement populaire
- Probl√®me : gradients qui "s'√©vanouissent" pour $|z|$ grand

### 4.2 Tangente hyperbolique (tanh)

$$
\tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}
$$

- Sort entre -1 et 1
- Centr√©e en 0 (mieux que sigmo√Øde)

### 4.3 ReLU (Rectified Linear Unit)

$$
\text{ReLU}(z) = \max(0, z)
$$

- **La plus utilis√©e** aujourd'hui
- Simple et efficace
- R√©sout le probl√®me des gradients √©vanescents
- Variantes : Leaky ReLU, ELU, GELU

### 4.4 La Sortie : Softmax (Classification Multi-classe)

Si on veut classer une image en 3 classes (Chat, Chien, Oiseau), la couche de sortie aura 3 neurones. Ils vont sortir des scores bruts (logits), par exemple : [2.0, 1.0, 0.1].
Pour transformer √ßa en probabilit√©s (qui somment √† 1), on utilise la fonction **Softmax** :

$$ P(y=j) = \frac{e^{z_j}}{\sum_{k} e^{z_k}} $$

Cela "√©crase" les scores pour qu'ils deviennent une distribution de probabilit√© (ex: [0.7, 0.2, 0.1]).

**Graphique comparatif** :

### 4.5 Visualisation Interactive

Comparez les diff√©rentes fonctions d'activation.
*   **Sigmo√Øde** : √âcrase tout entre 0 et 1.
*   **ReLU** : Laisse passer le positif, met √† z√©ro le n√©gatif. C'est la plus efficace pour les r√©seaux profonds.

<iframe class="embedded-notebook" src="/observables/activation-functions/" width="100%" height="500" frameborder="0" style="border: 1px solid #eee; border-radius: 8px;"></iframe>

---

## 5. Apprentissage : la descente de gradient

### 5.1 Fonction de co√ªt

Pour entra√Æner le r√©seau, on d√©finit une **fonction de co√ªt** $E$ qui mesure l'erreur :

$$
E(\mathbf{w}) = \frac{1}{N} \sum_{i=1}^{N} (\hat{y}_i - y_i)^2
$$

(Erreur quadratique moyenne pour la r√©gression)

### 5.2 Principe de la descente de gradient

On cherche les poids $\mathbf{w}$ qui **minimisent** $E$. Pour cela :

1. Calculer le **gradient** $\nabla E = \frac{\partial E}{\partial \mathbf{w}}$ (direction de plus forte mont√©e)
2. Mettre √† jour les poids dans la **direction oppos√©e** :

$$
w \leftarrow w - \eta \frac{\partial E}{\partial w}
$$

O√π $\eta$ est le **taux d'apprentissage** (learning rate), petit nombre comme 0.01.

### 5.3 M√©taphore visuelle

Imaginez que vous √™tes dans le brouillard au sommet d'une montagne (erreur √©lev√©e). Vous voulez descendre dans la vall√©e (erreur minimale). √Ä chaque pas :
- Vous sentez la pente sous vos pieds (gradient)
- Vous faites un pas dans la direction de descente
- Vous recommencez jusqu'√† atteindre le fond

**R√©tropropagation** (backpropagation) : algorithme efficace pour calculer les gradients en propageant l'erreur de la sortie vers l'entr√©e.

> **Note pour les matheux** : La r√©tropropagation n'est rien d'autre qu'une application r√©cursive du **th√©or√®me de d√©rivation des fonctions compos√©es** (Chain Rule).
> Si $y = f(g(x))$, alors $\frac{dy}{dx} = f'(g(x)) \times g'(x)$.
> Dans un r√©seau, l'erreur est une fonction compos√©e de milliers de couches : $E = L(f_n(...f_1(x)...))$. On remonte la cha√Æne des d√©riv√©es de la fin vers le d√©but.

---

## 6. Architectures modernes

### 6.1 R√©seaux convolutifs (CNN)

**Usage** : Vision par ordinateur, images

- **Convolutions** : d√©tection de motifs locaux (bords, textures, formes)
- **Pooling** : r√©duction de dimension
- Exemples : AlexNet, VGG, ResNet

### 6.2 R√©seaux r√©currents (RNN, LSTM)

**Usage** : S√©quences, texte, s√©ries temporelles

- **M√©moire** : prise en compte du contexte pass√©
- LSTM (Long Short-Term Memory) : r√©sout le probl√®me des gradients √©vanescents
- Applications : traduction, reconnaissance vocale

### 6.3 Transformers

**Usage** : Traitement du langage (GPT, BERT), vision (ViT)

- **Attention** : pond√©ration de l'importance des diff√©rents √©l√©ments
- Parall√©lisable (plus rapide que RNN)
- Base des LLM (Large Language Models) comme ChatGPT

### 6.4 R√©seaux g√©n√©ratifs

- **GAN** (Generative Adversarial Networks) : g√©n√©ration d'images r√©alistes
- **Diffusion Models** : DALL¬∑E, Stable Diffusion
- **VAE** (Variational Autoencoders) : compression et g√©n√©ration

---

## 7. En pratique

### 7.1 Frameworks populaires

- **PyTorch** : tr√®s utilis√© en recherche
- **TensorFlow / Keras** : √©cosyst√®me complet, bon pour la production
- **JAX** : calcul diff√©rentiable haute performance

### 7.2 Exemple simple en PyTorch

```python
import torch
import torch.nn as nn

# D√©finir un MLP simple
class SimpleMLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.layer1 = nn.Linear(10, 64)  # 10 entr√©es ‚Üí 64 neurones
        self.layer2 = nn.Linear(64, 32)  # 64 ‚Üí 32
        self.layer3 = nn.Linear(32, 1)   # 32 ‚Üí 1 sortie
        
    def forward(self, x):
        x = torch.relu(self.layer1(x))   # ReLU activation
        x = torch.relu(self.layer2(x))
        x = self.layer3(x)               # Pas d'activation en sortie
        return x

# Cr√©er le mod√®le
model = SimpleMLP()

# D√©finir la fonction de co√ªt et l'optimiseur
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

# Boucle d'entra√Ænement (simplifi√©)
for epoch in range(100):
    # Forward pass
    predictions = model(X_train)
    loss = criterion(predictions, y_train)
    
    # Backward pass
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
```

---

## 8. Points cl√©s √† retenir

- Un **perceptron** est un classifieur lin√©aire simple : $y = \text{sign}(\mathbf{w} \cdot \mathbf{x} + b)$
- Les perceptrons seuls ne peuvent r√©soudre que des probl√®mes **lin√©airement s√©parables**
- Les **r√©seaux multicouches** (MLP) ajoutent des couches cach√©es avec activation non lin√©aire
- Les fonctions d'activation (ReLU, sigmo√Øde, tanh) apportent la **non-lin√©arit√©**
- L'apprentissage se fait par **descente de gradient** : ajuster les poids pour minimiser l'erreur
- Les architectures modernes (CNN, RNN, Transformers) sont des r√©seaux profonds sp√©cialis√©s

---

## üîó Pour aller plus loin

- **3Blue1Brown** : [s√©rie vid√©o sur les r√©seaux de neurones](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) (excellente visualisation)
- **Distill.pub** : [articles interactifs sur le deep learning](https://distill.pub/)
- **Cours Stanford CS231n** : [vision par ordinateur et CNN](http://cs231n.stanford.edu/)
- **The Neural Network Zoo** : [panorama des architectures](https://www.asimovinstitute.org/neural-network-zoo/)

---

**Prochain chapitre** : [Chapitre 6 ‚Äî Deep Learning et IA G√©n√©rative](/cours/CM6/)
