---
title: "TD 4 ‚Äî Clustering K-Means"
---

## üéØ Objectifs

- D√©rouler l'algorithme K-Means manuellement.
- Comprendre la convergence.
- Interpr√©ter la m√©thode du coude.
- D√©couvrir le Clustering Hi√©rarchique.

---

## Exercice 1 : K-Means √† la main

On dispose de 4 points sur une droite (1D) :
*   A = 2
*   B = 3
*   C = 10
*   D = 11

On veut faire un clustering avec **K=2**.

**Initialisation :**
On choisit au hasard deux centres :
*   $C_1 = 2$ (sur le point A)
*   $C_2 = 10$ (sur le point C)

**It√©ration 1 :**
1.  **Affectation** : Pour chaque point (A, B, C, D), calculez sa distance √† $C_1$ et $C_2$. Attribuez le point au centre le plus proche.
    *   Quels points sont dans le Cluster 1 ?
    *   Quels points sont dans le Cluster 2 ?
2.  **Mise √† jour** : Calculez la nouvelle position des centres.
    *   Nouveau $C_1$ = Moyenne des points du Cluster 1.
    *   Nouveau $C_2$ = Moyenne des points du Cluster 2.

**It√©ration 2 :**
3.  **Affectation** : Recalculez les distances avec les nouveaux centres. Les groupes changent-ils ?
4.  **Mise √† jour** : Recalculez les centres.

**Conclusion :**
L'algorithme a-t-il converg√© ? Les groupes (2,3) et (10,11) vous semblent-ils logiques ?

---

## Exercice 2 : La M√©thode du Coude (Elbow Method)

On a ex√©cut√© K-Means pour diff√©rentes valeurs de K sur un dataset complexe.
Voici l'√©volution de l'**Inertie Intra-Classe** (somme des distances carr√©es points-centres) :

*   K=1 : Inertie = 5000
*   K=2 : Inertie = 1500
*   K=3 : Inertie = 400
*   K=4 : Inertie = 350
*   K=5 : Inertie = 320

**Questions :**
1.  Tracez grossi√®rement la courbe Inertie = f(K).
2.  Pourquoi l'inertie diminue-t-elle toujours quand K augmente ?
3.  O√π se situe le "coude" ?
4.  Quel est le nombre optimal de clusters selon vous ? Pourquoi ne pas choisir K=5 ?

---

## Exercice 3 : Probl√®mes potentiels

K-Means utilise la moyenne.
Imaginez un cluster avec 99 points regroup√©s autour de 0, et 1 point aberrant (outlier) situ√© √† 1000.

**Questions :**
1.  O√π sera le centre de ce cluster ?
2.  Est-ce repr√©sentatif de la majorit√© des points ?
3.  Quelle m√©trique de centralit√© serait plus robuste que la moyenne ? (Indice : M√©diane).

---

## Exercice 4 : Clustering Hi√©rarchique (Single Linkage)

On reprend nos 4 points : A=2, B=3, C=10, D=11.
On veut construire un dendrogramme avec l'approche "Single Linkage" (distance entre clusters = distance entre les deux points les plus proches).

**√âtapes :**
1.  Au d√©part, on a 4 clusters : {A}, {B}, {C}, {D}.
2.  Quels sont les 2 clusters les plus proches ? Fusionnez-les. Quelle est la distance de fusion ?
3.  Il reste 3 clusters. Quels sont les plus proches ? (Attention, distance {AB} vers {C} = min(dist(A,C), dist(B,C))).
4.  Continuez jusqu'√† n'avoir qu'un seul cluster.
5.  Dessinez le dendrogramme (Arbre des fusions).
